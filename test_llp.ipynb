{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/27 20:41:33 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 192.168.102.123 instead (on interface ens192)\n",
      "23/11/27 20:41:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/27 20:41:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "# 创建SparkSession\n",
    "spark = SparkSession.builder.appName(\"MovieRecommend\")\\\n",
    "    .config(\"spark.executor.memory\", \"8G\")\\\n",
    "    .config(\"spark.executor.cores\", \"4\")\\\n",
    "    .config(\"spark.executor.instances\", \"4\")\\\n",
    "    .config(\"spark.driver.memory\", \"8G\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "ratings_df = spark.read.csv(\"dataset/ratings.csv\", inferSchema=True, header=True)\n",
    "\n",
    "# Read additional data\n",
    "tags_df = spark.read.csv(\"dataset/tags.csv\", header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(\"dataset/movies.csv\", header=True, inferSchema=True)\n",
    "genome_scores_df = spark.read.csv(\"dataset/genome-scores.csv\", header=True, inferSchema=True)\n",
    "genome_tags_df = spark.read.csv(\"dataset/genome-tags.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join DataFrames\n",
    "# complete_data = movies_df.join(tags_df, \"movieId\") \\\n",
    "#                         .join(genome_scores_df, \"movieId\") \\\n",
    "#                         .join(genome_tags_df, \"tagId\") \\\n",
    "#                         .join(ratings_df, [\"userId\", \"movieId\"])\n",
    "\n",
    "# genome_data=genome_scores_df.join(genome_tags_df,\"tagId\")\n",
    "\n",
    "# complete_data=ratings_df.join(movies_df,\"movieId\")\\\n",
    "# .join(tags_df,\"movieId\")\\\n",
    "# .join(genome_data,[\"movieId\",\"tag\"])\n",
    "\n",
    "# complete_data.printSchema()\n",
    "# # complete_data.show(5)\n",
    "# complete_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def add_sample_label(ratings_df):\n",
    "    # Show the first 5 rows and print the schema before modification\n",
    "    ratings_df.show(5, truncate=False)\n",
    "    ratings_df.printSchema()\n",
    "\n",
    "    # Add a new column 'label' based on the condition\n",
    "    ratings_df = ratings_df.withColumn('label', F.when(F.col('rating') >= 3.5, 2).otherwise(3))\n",
    "\n",
    "    return ratings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Extract movie year\n",
    "def parse_year(title):\n",
    "    pattern = r\"\\((\\d{4})\\)\"  # 正则表达式模式，匹配括号内的四位数字\n",
    "    match = re.search(pattern, title)\n",
    "    if match:\n",
    "        year_str = match.group(1)\n",
    "        return int(year_str)\n",
    "    else:\n",
    "        return 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|timestamp |\n",
      "+------+-------+------+----------+\n",
      "|1     |296    |5.0   |1147880044|\n",
      "|1     |306    |3.5   |1147868817|\n",
      "|1     |307    |5.0   |1147868828|\n",
      "|1     |665    |5.0   |1147878820|\n",
      "|1     |899    |3.5   |1147868510|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      " |-- movie_year: integer (nullable = true)\n",
      " |-- genres_(no genres listed): integer (nullable = true)\n",
      " |-- genres_Action: integer (nullable = true)\n",
      " |-- genres_Mystery: integer (nullable = true)\n",
      " |-- genres_Documentary: integer (nullable = true)\n",
      " |-- genres_Adventure: integer (nullable = true)\n",
      " |-- genres_War: integer (nullable = true)\n",
      " |-- genres_Fantasy: integer (nullable = true)\n",
      " |-- genres_Children: integer (nullable = true)\n",
      " |-- genres_Animation: integer (nullable = true)\n",
      " |-- genres_Comedy: integer (nullable = true)\n",
      " |-- genres_Horror: integer (nullable = true)\n",
      " |-- genres_Crime: integer (nullable = true)\n",
      " |-- genres_Film-Noir: integer (nullable = true)\n",
      " |-- genres_Thriller: integer (nullable = true)\n",
      " |-- genres_Sci-Fi: integer (nullable = true)\n",
      " |-- genres_Western: integer (nullable = true)\n",
      " |-- genres_Drama: integer (nullable = true)\n",
      " |-- genres_IMAX: integer (nullable = true)\n",
      " |-- genres_Musical: integer (nullable = true)\n",
      " |-- genres_Romance: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/27 20:41:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+-----+----------+-------------------------+-------------+--------------+------------------+----------------+----------+--------------+---------------+----------------+-------------+-------------+------------+----------------+---------------+-------------+--------------+------------+-----------+--------------+--------------+\n",
      "|movieId|userId|rating|timestamp|label|movie_year|genres_(no genres listed)|genres_Action|genres_Mystery|genres_Documentary|genres_Adventure|genres_War|genres_Fantasy|genres_Children|genres_Animation|genres_Comedy|genres_Horror|genres_Crime|genres_Film-Noir|genres_Thriller|genres_Sci-Fi|genres_Western|genres_Drama|genres_IMAX|genres_Musical|genres_Romance|\n",
      "+-------+------+------+---------+-----+----------+-------------------------+-------------+--------------+------------------+----------------+----------+--------------+---------------+----------------+-------------+-------------+------------+----------------+---------------+-------------+--------------+------------+-----------+--------------+--------------+\n",
      "|    296|     1|   5.0|       36|    2|      1994|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            1|            0|           1|               0|              1|            0|             0|           1|          0|             0|             0|\n",
      "|    306|     1|   3.5|       36|    2|      1994|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|    307|     1|   5.0|       36|    2|      1993|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|    665|     1|   5.0|       36|    2|      1995|                        0|            0|             0|                 0|               0|         1|             0|              0|               0|            1|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|    899|     1|   3.5|       36|    2|      1952|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            1|            0|           0|               0|              0|            0|             0|           0|          0|             1|             1|\n",
      "|   1088|     1|   4.0|       36|    2|      1987|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             1|             1|\n",
      "|   1175|     1|   3.5|       36|    2|      1991|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            1|            0|           0|               0|              0|            0|             0|           1|          0|             0|             1|\n",
      "|   1217|     1|   3.5|       36|    2|      1985|                        0|            0|             0|                 0|               0|         1|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   1237|     1|   5.0|       36|    2|      1957|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   1250|     1|   4.0|       36|    2|      1957|                        0|            0|             0|                 0|               1|         1|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   1260|     1|   3.5|       36|    2|      1931|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           1|               1|              1|            0|             0|           0|          0|             0|             0|\n",
      "|   1653|     1|   4.0|       36|    2|      1997|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              1|            1|             0|           1|          0|             0|             0|\n",
      "|   2011|     1|   2.5|       36|    3|      1989|                        0|            0|             0|                 0|               1|         0|             0|              0|               0|            1|            0|           0|               0|              0|            1|             0|           0|          0|             0|             0|\n",
      "|   2012|     1|   2.5|       36|    3|      1990|                        0|            0|             0|                 0|               1|         0|             0|              0|               0|            1|            0|           0|               0|              0|            1|             1|           0|          0|             0|             0|\n",
      "|   2068|     1|   2.5|       36|    3|      1982|                        0|            0|             1|                 0|               0|         0|             1|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   2161|     1|   3.5|       36|    2|      1984|                        0|            0|             0|                 0|               1|         0|             1|              1|               0|            0|            0|           0|               0|              0|            0|             0|           0|          0|             0|             0|\n",
      "|   2351|     1|   4.5|       36|    2|      1957|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   2573|     1|   4.0|       36|    2|      1998|                        0|            0|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             1|             0|\n",
      "|   2632|     1|   5.0|       36|    2|      1965|                        0|            0|             1|                 0|               1|         0|             0|              0|               0|            0|            0|           0|               0|              0|            0|             0|           1|          0|             0|             0|\n",
      "|   2692|     1|   5.0|       36|    2|      1998|                        0|            1|             0|                 0|               0|         0|             0|              0|               0|            0|            0|           1|               0|              0|            0|             0|           0|          0|             0|             0|\n",
      "+-------+------+------+---------+-----+----------+-------------------------+-------------+--------------+------------------+----------------+----------+--------------+---------------+----------------+-------------+-------------+------------+----------------+---------------+-------------+--------------+------------+-----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import os\n",
    "import pickle\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# # spark = SparkSession.builder.appName(\"PrepareData\").getOrCreate()\n",
    "# # 创建SparkSession\n",
    "# spark = SparkSession.builder.appName(\"MovieRecommend\")\\\n",
    "#     .config(\"spark.executor.memory\", \"8G\")\\\n",
    "#     .config(\"spark.executor.cores\", \"4\")\\\n",
    "#     .config(\"spark.executor.instances\", \"4\")\\\n",
    "#     .config(\"spark.driver.memory\", \"8G\")\\\n",
    "#     .getOrCreate()\n",
    "\n",
    "\n",
    "# Read movie data\n",
    "data_path = \"dataset/\"\n",
    "df_movie = spark.read.csv(\n",
    "    \"dataset/movies.csv\", header=True,inferSchema=True)\n",
    "\n",
    "# Extract movie year\n",
    "parse_year_udf = udf(parse_year, IntegerType())\n",
    "df_movie = df_movie.withColumn(\"movie_year\", parse_year_udf(df_movie['title']))\n",
    "df_movie=df_movie.drop('title')\n",
    "\n",
    "# # Join genome data to df\n",
    "# df = df.join(genome_scores_df, \"movieId\")\n",
    "# df = df.join(genome_tags_df, \"tagId\")\n",
    "\n",
    "# One-hot encoding genres\n",
    "genres = df_movie.select(\"genres\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "genres_unique = list(set([i for sublist in genres for i in sublist.split(\"|\")]))\n",
    "\n",
    "for genres_name in genres_unique:\n",
    "    col = \"genres_\" + genres_name\n",
    "    df_movie = df_movie.withColumn(col, \n",
    "                                   (df_movie.genres.contains(genres_name)).cast(IntegerType()))\n",
    "\n",
    "df_movie = df_movie.drop('genres')\n",
    "genres_col_names = [\"genres_\" + x for x in genres_unique]\n",
    "\n",
    "# Read rating data\n",
    "\n",
    "df_rating = spark.read.csv(\n",
    "    \"dataset/ratings.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df_rating = add_sample_label(df_rating)\n",
    "df_rating = df_rating.withColumn('timestamp', (df_rating['timestamp'] / (365 * 24 * 3600)).cast(IntegerType()))\n",
    "\n",
    "# Data merge\n",
    "df = df_rating.join(df_movie, 'movieId')\n",
    "\n",
    "\n",
    "# df_X = df.select([\"userId\", \"movieId\"] + genres_col_names + [\"timestamp\"])\n",
    "# df_y = df.select([\"rating\"])\n",
    "# print(\"Data read completed\")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(20)\n",
    "# df_X.show(10)\n",
    "# df_y.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "\n",
    "# 定义评估器\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# 定义评估器和评估方法\n",
    "evaluator = RegressionEvaluator(labelCol=\"rating\", metricName=\"rmse\")\n",
    "\n",
    "# 定义训练验证拆分\n",
    "tvs = TrainValidationSplit(estimator=rf,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=0.7)  # 训练比例\n",
    "\n",
    "# 记录每次训练的时间和性能\n",
    "results = []\n",
    "\n",
    "for param_map in param_grid:\n",
    "    start_time = time.time()\n",
    "    model = rf.fit(training_data, param_map)\n",
    "    end_time = time.time()\n",
    "\n",
    "    predictions = model.transform(test_data)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    results.append({\n",
    "        \"params\": param_map,\n",
    "        \"rmse\": rmse,\n",
    "        \"training_time\": training_time\n",
    "    })\n",
    "\n",
    "# 输出每次训练的时间和性能\n",
    "for result in results:\n",
    "    print(\"Parameters:\", result[\"params\"])\n",
    "    print(\"RMSE:\", result[\"rmse\"])\n",
    "    print(\"Training time:\", result[\"training_time\"])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read completed\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# 使用 VectorAssembler 进行特征组合\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"userId\", \"movieId\", \"timestamp\",\"movie_year\",\"label\"] + genres_col_names ,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 对数据框进行转换\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# 打印数据读取完成的消息\n",
    "print(\"Data read completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/27 20:43:12 WARN MemoryStore: Not enough space to cache rdd_117_3 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:12 WARN BlockManager: Persisting block rdd_117_3 to disk instead.\n",
      "23/11/27 20:43:12 WARN MemoryStore: Not enough space to cache rdd_117_10 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:12 WARN BlockManager: Persisting block rdd_117_10 to disk instead.\n",
      "23/11/27 20:43:12 WARN MemoryStore: Not enough space to cache rdd_117_9 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:12 WARN BlockManager: Persisting block rdd_117_9 to disk instead.\n",
      "23/11/27 20:43:12 WARN MemoryStore: Not enough space to cache rdd_117_5 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:12 WARN BlockManager: Persisting block rdd_117_5 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_4 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_4 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_2 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_2 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_0 in memory! (computed 104.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_0 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_7 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_7 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_1 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_1 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_8 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_8 to disk instead.\n",
      "23/11/27 20:43:13 WARN MemoryStore: Not enough space to cache rdd_117_12 in memory! (computed 156.0 MiB so far)\n",
      "23/11/27 20:43:13 WARN BlockManager: Persisting block rdd_117_12 to disk instead.\n",
      "23/11/27 20:43:14 WARN MemoryStore: Not enough space to cache rdd_117_13 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:14 WARN BlockManager: Persisting block rdd_117_13 to disk instead.\n",
      "23/11/27 20:43:14 WARN MemoryStore: Not enough space to cache rdd_117_14 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:14 WARN BlockManager: Persisting block rdd_117_14 to disk instead.\n",
      "23/11/27 20:43:14 WARN MemoryStore: Not enough space to cache rdd_117_11 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:14 WARN BlockManager: Persisting block rdd_117_11 to disk instead.\n",
      "23/11/27 20:43:14 WARN MemoryStore: Not enough space to cache rdd_117_6 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:14 WARN BlockManager: Persisting block rdd_117_6 to disk instead.\n",
      "23/11/27 20:43:25 WARN MemoryStore: Not enough space to cache rdd_117_2 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:25 WARN MemoryStore: Not enough space to cache rdd_117_1 in memory! (computed 234.0 MiB so far)\n",
      "23/11/27 20:43:34 WARN MemoryStore: Not enough space to cache rdd_117_1 in memory! (computed 234.0 MiB so far)\n",
      "[Stage 36:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.620166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "\n",
    "# 选择特征和目标列\n",
    "df = df.select(\"features\", \"rating\")\n",
    "\n",
    "# 划分数据集为训练集和测试集\n",
    "(training_data, test_data) = df.randomSplit([0.7, 0.3],seed=123)\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"rating\",\n",
    "    numTrees=10,\n",
    "    maxDepth=5,\n",
    "    maxBins=32,\n",
    "    minInstancesPerNode=1\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model_rf = rf.fit(training_data)\n",
    "\n",
    "# Predicting on test data\n",
    "predictions_rf = model_rf.transform(test_data)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions_rf)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
